# translate.py

from transformers import MarianMTModel, MarianTokenizer

# HuggingFace –¥—ç—ç—Ä—Ö –∞–Ω–≥–ª–∏ ‚ûù –º–æ–Ω–≥–æ–ª –∑–∞–≥–≤–∞—Ä
MODEL_NAME = "Helsinki-NLP/opus-mt-en-mn"

# –ó–∞–≥–≤–∞—Ä –±–æ–ª–æ–Ω tokenizer –∞—á–∞–∞–ª–ª–∞—Ö
tokenizer = MarianTokenizer.from_pretrained(MODEL_NAME)
model = MarianMTModel.from_pretrained(MODEL_NAME)

def translate_text(transcript_path):
    # –¢–µ–∫—Å—Ç —Ñ–∞–π–ª—ã–≥ —É–Ω—à–∏–Ω–∞
    with open(transcript_path, "r", encoding="utf-8") as f:
        original_text = f.read()

    # –•—ç—Ç —É—Ä—Ç –±–æ–ª —Ö—ç—Å—ç–≥—á–∏–ª–Ω—ç
    sentences = original_text.strip().split(". ")
    translated_chunks = []

    print("üåê –û—Ä—á—É—É–ª–≥–∞ —Ö–∏–π–∂ –±–∞–π–Ω–∞...")

    for sentence in sentences:
        if sentence.strip() == "":
            continue
        inputs = tokenizer(sentence, return_tensors="pt", padding=True, truncation=True)
        translated = model.generate(**inputs)
        translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)
        translated_chunks.append(translated_text)

    full_translation = ". ".join(translated_chunks)

    # –û—Ä—á—É—É–ª—Å–∞–Ω —Ç–µ–∫—Å—Ç–∏–π–≥ —Ñ–∞–π–ª–¥ —Ö–∞–¥–≥–∞–ª–Ω–∞
    translated_path = transcript_path.replace("_transcript.txt", "_translated.txt")
    with open(translated_path, "w", encoding="utf-8") as f:
        f.write(full_translation)

    print("‚úÖ –û—Ä—á—É—É–ª–≥–∞ –∞–º–∂–∏–ª—Ç—Ç–∞–π –±–æ–ª–ª–æ–æ!")
    return translated_path
